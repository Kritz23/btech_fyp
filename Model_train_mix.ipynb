{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 32675 files [02:12, 246.94 files/s] \n"
     ]
    }
   ],
   "source": [
    "import splitfolders  # or import split_folders\n",
    "\n",
    "# Split with a ratio.\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio(\"/home/kritika/Downloads/FYP/dataset/GTSRB/mix_data/\", output=\"/home/kritika/Downloads/FYP/dataset/GTSRB/split_data/\", seed=1337, ratio=(.7, .2, .1), group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "path = \"/home/kritika/Downloads/FYP/dataset/GTSRB/mix_data/\"\n",
    "\n",
    "for folder in range(43):\n",
    "    for img in os.listdir(path+str(folder)):\n",
    "        image = Image.open(path+str(folder)+\"/\"+img)\n",
    "        if image.mode == \"RGBA\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "        image = transform.resize(image, (32, 32))\n",
    "        # update the list of data and labels, respectively\n",
    "        data.append(image)\n",
    "        labels.append(int(folder))\n",
    "        \n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32675, 32, 32, 3) (32675,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data.npy', data)\n",
    "np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24506, 32, 32, 3) (8169, 32, 32, 3) (24506,) (8169,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(data,labels,test_size=0.25,random_state=42, stratify = labels)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape,y_test.shape)\n",
    "\n",
    "y_train = to_categorical(y_train,43)\n",
    "y_test = to_categorical(y_test,43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "#Compiling the model with adam optimizer\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 356,939\n",
      "Trainable params: 356,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "383/383 [==============================] - 81s 206ms/step - loss: 3.2551 - accuracy: 0.1381 - val_loss: 1.3899 - val_accuracy: 0.6337\n",
      "Epoch 2/20\n",
      "383/383 [==============================] - 74s 192ms/step - loss: 1.4835 - accuracy: 0.5857 - val_loss: 0.9511 - val_accuracy: 0.7465\n",
      "Epoch 3/20\n",
      "383/383 [==============================] - 74s 194ms/step - loss: 1.1142 - accuracy: 0.6848 - val_loss: 0.7719 - val_accuracy: 0.7837\n",
      "Epoch 4/20\n",
      "383/383 [==============================] - 74s 192ms/step - loss: 0.9619 - accuracy: 0.7247 - val_loss: 0.6938 - val_accuracy: 0.8013\n",
      "Epoch 5/20\n",
      "383/383 [==============================] - 74s 194ms/step - loss: 0.8684 - accuracy: 0.7430 - val_loss: 0.6577 - val_accuracy: 0.8139\n",
      "Epoch 6/20\n",
      "383/383 [==============================] - 74s 193ms/step - loss: 0.7817 - accuracy: 0.7728 - val_loss: 0.6282 - val_accuracy: 0.8183\n",
      "Epoch 7/20\n",
      "383/383 [==============================] - 74s 193ms/step - loss: 0.7152 - accuracy: 0.7869 - val_loss: 0.5655 - val_accuracy: 0.8305\n",
      "Epoch 8/20\n",
      "383/383 [==============================] - 74s 193ms/step - loss: 0.6545 - accuracy: 0.8007 - val_loss: 0.5508 - val_accuracy: 0.8378\n",
      "Epoch 9/20\n",
      "383/383 [==============================] - 74s 194ms/step - loss: 0.6149 - accuracy: 0.8158 - val_loss: 0.5266 - val_accuracy: 0.8448\n",
      "Epoch 10/20\n",
      "383/383 [==============================] - 74s 193ms/step - loss: 0.6096 - accuracy: 0.8156 - val_loss: 0.5182 - val_accuracy: 0.8513\n",
      "Epoch 11/20\n",
      "383/383 [==============================] - 75s 195ms/step - loss: 0.5741 - accuracy: 0.8244 - val_loss: 0.4952 - val_accuracy: 0.8574\n",
      "Epoch 12/20\n",
      "383/383 [==============================] - 74s 194ms/step - loss: 0.5412 - accuracy: 0.8350 - val_loss: 0.5058 - val_accuracy: 0.8544\n",
      "Epoch 13/20\n",
      "383/383 [==============================] - 75s 195ms/step - loss: 0.5270 - accuracy: 0.8383 - val_loss: 0.4667 - val_accuracy: 0.8635\n",
      "Epoch 14/20\n",
      "383/383 [==============================] - 74s 193ms/step - loss: 0.5105 - accuracy: 0.8388 - val_loss: 0.4832 - val_accuracy: 0.8602\n",
      "Epoch 15/20\n",
      "383/383 [==============================] - 74s 194ms/step - loss: 0.5100 - accuracy: 0.8414 - val_loss: 0.4528 - val_accuracy: 0.8641\n",
      "Epoch 16/20\n",
      "383/383 [==============================] - 74s 193ms/step - loss: 0.4895 - accuracy: 0.8496 - val_loss: 0.4584 - val_accuracy: 0.8646\n",
      "Epoch 17/20\n",
      "383/383 [==============================] - 74s 194ms/step - loss: 0.4712 - accuracy: 0.8520 - val_loss: 0.4493 - val_accuracy: 0.8663\n",
      "Epoch 18/20\n",
      "383/383 [==============================] - 75s 195ms/step - loss: 0.4577 - accuracy: 0.8564 - val_loss: 0.4364 - val_accuracy: 0.8738\n",
      "Epoch 19/20\n",
      "383/383 [==============================] - 75s 195ms/step - loss: 0.4565 - accuracy: 0.8602 - val_loss: 0.4493 - val_accuracy: 0.8712\n",
      "Epoch 20/20\n",
      "383/383 [==============================] - 74s 194ms/step - loss: 0.4390 - accuracy: 0.8649 - val_loss: 0.4337 - val_accuracy: 0.8727\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=epochs, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('traffic_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
